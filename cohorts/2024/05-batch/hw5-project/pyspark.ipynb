{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c684e4-4655-41eb-979f-7c738ff9d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e62bb42-95ab-4965-a0f9-20e8d53a410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1: Spark version\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6bad96c-b3e0-4078-9583-06e29f72392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/03 13:48:49 WARN Utils: Your hostname, hy-virtual-machine resolves to a loopback address: 127.0.1.1; using 172.16.167.128 instead (on interface ens160)\n",
      "24/03/03 13:48:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/03 13:48:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90bd2d0-a98e-4224-a62e-5995aae4079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-03 13:49:07--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240303%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240303T214908Z&X-Amz-Expires=300&X-Amz-Signature=9052e0f30351098ed4fa796f1914f7ab51ad3e2a8c09a111db1b944486e34deb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-03 13:49:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240303%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240303T214908Z&X-Amz-Expires=300&X-Amz-Signature=9052e0f30351098ed4fa796f1914f7ab51ad3e2a8c09a111db1b944486e34deb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  64.2MB/s    in 0.3s    \n",
      "\n",
      "2024-03-03 13:49:08 (64.2 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5dc652-d757-4dd7-bcc5-81382c2e0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -c fhv_tripdata_2019-10.csv.gz > fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d98ed1e-da2c-4281-b819-7186f3321c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897494 fhv_tripdata_2019-10.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30fe8a8f-cca6-4922-a0c5-35f5d6a7d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf004b23-50ad-4e54-9ac6-4421063adfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bc3590-234f-4301-89b1-3ed8793efd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1001 fhv_tripdata_2019-10.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b561b79-0008-4ca0-a111-f2ef4af7fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "340bd65b-589b-4acf-9be4-08a66feea76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2fa810-1dc4-48ba-bf3b-486c098cc40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID              float64\n",
       "DOlocationID              float64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85eab792-e297-4a05-b65e-5445a873fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914b2ab5-7e0a-47e1-aec3-4108018f5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7feae0d-a865-4808-9d98-e22fe1861700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0332aca-b394-4dd3-923c-ff72dc2e777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Partition the dataframe into 6 paquet\n",
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86de2295-cd89-4998-994a-53aa3038183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acccc116-03c6-458b-87b7-f026f6fcfbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start here - Read data from parquets\n",
    "df = spark.read.parquet('fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81e05f89-a45a-4902-ae8c-cf9a8c3a5e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a415ba3-13d8-493c-8bcf-b43343de7ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|     B01215         |2019-10-07 08:36:04|2019-10-07 08:51:10|         223|         223|   null|       B01215         |\n",
      "|              B01190|2019-10-04 12:43:20|2019-10-04 13:03:28|         264|          66|   null|                B01190|\n",
      "|              B00937|2019-10-05 19:05:00|2019-10-05 19:07:16|         264|         243|   null|                B00937|\n",
      "|              B02735|2019-10-04 15:29:27|2019-10-04 15:51:24|         264|         265|   null|                B02872|\n",
      "|              B00856|2019-10-07 07:45:22|2019-10-07 07:52:47|         264|          76|   null|                B02871|\n",
      "|              B00647|2019-10-06 04:46:33|2019-10-06 04:49:45|         264|         242|   null|                B00647|\n",
      "|              B00887|2019-10-05 15:55:08|2019-10-05 16:17:59|         264|         229|   null|                B00887|\n",
      "|              B01339|2019-10-04 00:13:52|2019-10-04 00:29:22|         264|         119|   null|                B01339|\n",
      "|              B00900|2019-10-07 13:58:22|2019-10-07 14:06:07|         264|         134|   null|                B00900|\n",
      "|              B00254|2019-10-02 09:34:12|2019-10-02 10:12:04|         143|         138|   null|                B00254|\n",
      "|              B01233|2019-10-05 10:36:14|2019-10-05 10:55:56|         264|          78|   null|                B01233|\n",
      "|              B01194|2019-10-06 06:49:03|2019-10-06 07:08:58|         264|         157|   null|                B01194|\n",
      "|              B01196|2019-10-05 00:18:57|2019-10-05 00:22:35|         264|         244|   null|                B01196|\n",
      "|              B03032|2019-10-08 13:40:05|2019-10-08 13:49:25|         264|          17|   null|                B03032|\n",
      "|              B01061|2019-10-03 10:09:00|2019-10-03 10:39:10|         264|          69|   null|                B01061|\n",
      "|              B03156|2019-10-03 08:24:00|2019-10-03 08:36:00|         243|         140|   null|                B03156|\n",
      "|              B01985|2019-10-02 10:22:00|2019-10-02 10:41:00|         264|         264|   null|                B01985|\n",
      "|              B03016|2019-10-06 12:00:39|2019-10-06 12:19:29|         264|          94|   null|                B02875|\n",
      "|              B00310|2019-10-05 12:17:22|2019-10-05 12:21:46|         264|         167|   null|                B00310|\n",
      "|              B01087|2019-10-03 22:14:11|2019-10-03 22:22:09|         138|          74|   null|                B01087|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f22856d6-840c-4b6e-8b72-78de997562ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|pickup_date|dropoff_date|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "|     B01215         |2019-10-07 08:36:04|2019-10-07 08:51:10|         223|         223|   null|       B01215         | 2019-10-07|  2019-10-07|\n",
      "|              B01190|2019-10-04 12:43:20|2019-10-04 13:03:28|         264|          66|   null|                B01190| 2019-10-04|  2019-10-04|\n",
      "|              B00937|2019-10-05 19:05:00|2019-10-05 19:07:16|         264|         243|   null|                B00937| 2019-10-05|  2019-10-05|\n",
      "|              B02735|2019-10-04 15:29:27|2019-10-04 15:51:24|         264|         265|   null|                B02872| 2019-10-04|  2019-10-04|\n",
      "|              B00856|2019-10-07 07:45:22|2019-10-07 07:52:47|         264|          76|   null|                B02871| 2019-10-07|  2019-10-07|\n",
      "|              B00647|2019-10-06 04:46:33|2019-10-06 04:49:45|         264|         242|   null|                B00647| 2019-10-06|  2019-10-06|\n",
      "|              B00887|2019-10-05 15:55:08|2019-10-05 16:17:59|         264|         229|   null|                B00887| 2019-10-05|  2019-10-05|\n",
      "|              B01339|2019-10-04 00:13:52|2019-10-04 00:29:22|         264|         119|   null|                B01339| 2019-10-04|  2019-10-04|\n",
      "|              B00900|2019-10-07 13:58:22|2019-10-07 14:06:07|         264|         134|   null|                B00900| 2019-10-07|  2019-10-07|\n",
      "|              B00254|2019-10-02 09:34:12|2019-10-02 10:12:04|         143|         138|   null|                B00254| 2019-10-02|  2019-10-02|\n",
      "|              B01233|2019-10-05 10:36:14|2019-10-05 10:55:56|         264|          78|   null|                B01233| 2019-10-05|  2019-10-05|\n",
      "|              B01194|2019-10-06 06:49:03|2019-10-06 07:08:58|         264|         157|   null|                B01194| 2019-10-06|  2019-10-06|\n",
      "|              B01196|2019-10-05 00:18:57|2019-10-05 00:22:35|         264|         244|   null|                B01196| 2019-10-05|  2019-10-05|\n",
      "|              B03032|2019-10-08 13:40:05|2019-10-08 13:49:25|         264|          17|   null|                B03032| 2019-10-08|  2019-10-08|\n",
      "|              B01061|2019-10-03 10:09:00|2019-10-03 10:39:10|         264|          69|   null|                B01061| 2019-10-03|  2019-10-03|\n",
      "|              B03156|2019-10-03 08:24:00|2019-10-03 08:36:00|         243|         140|   null|                B03156| 2019-10-03|  2019-10-03|\n",
      "|              B01985|2019-10-02 10:22:00|2019-10-02 10:41:00|         264|         264|   null|                B01985| 2019-10-02|  2019-10-02|\n",
      "|              B03016|2019-10-06 12:00:39|2019-10-06 12:19:29|         264|          94|   null|                B02875| 2019-10-06|  2019-10-06|\n",
      "|              B00310|2019-10-05 12:17:22|2019-10-05 12:21:46|         264|         167|   null|                B00310| 2019-10-05|  2019-10-05|\n",
      "|              B01087|2019-10-03 22:14:11|2019-10-03 22:22:09|         138|          74|   null|                B01087| 2019-10-03|  2019-10-03|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d981b66-cd00-4da3-a1e0-355d7907ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pickup_datetime and dropoff_datetime from timestamp to date only\n",
    "df = df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a8abda3-7397-442a-a6a5-f3aa88c5a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Table from dataframe\n",
    "df.registerTempTable('fhv_2019_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27796cd8-13e0-4d5b-8aee-f5e2597eba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3: Count the trips that pickup_date is 2019-10-15 \n",
    "df.filter(df.pickup_date == '2019-10-15') \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6680124-216a-4982-a5c7-0c522169fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|pickup_date|dropoff_date|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "|              B02832|2019-10-28 09:00:00|2091-10-28 09:30:00|         264|         264|   null|                B02832| 2019-10-28|  2091-10-28|\n",
      "|              B02832|2019-10-11 18:00:00|2091-10-11 18:30:00|         264|         264|   null|                B02832| 2019-10-11|  2091-10-11|\n",
      "|              B02416|2019-10-31 23:46:33|2029-11-01 00:13:00|        null|        null|   null|                B02416| 2019-10-31|  2029-11-01|\n",
      "|     B00746         |2019-10-01 21:43:42|2027-10-01 21:45:23|         159|         264|   null|       B00746         | 2019-10-01|  2027-10-01|\n",
      "|              B03110|2019-10-26 21:26:00|2020-10-26 21:36:00|         264|         264|   null|                B03110| 2019-10-26|  2020-10-26|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy('dropoff_datetime', ascending=False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dcb3c7c-0937-423d-a279-58766742d3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|pickup_date|    max(duration)|\n",
      "+-----------+-----------------+\n",
      "| 2019-10-28|         631152.5|\n",
      "| 2019-10-11|         631152.5|\n",
      "| 2019-10-31|87672.44083333333|\n",
      "| 2019-10-01|70128.02805555555|\n",
      "| 2019-10-17|           8794.0|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Longest trip for each day \n",
    "df \\\n",
    "    .withColumn('duration', (df.dropoff_datetime.cast('long') - df.pickup_datetime.cast('long'))/3600) \\\n",
    "    .groupBy('pickup_date') \\\n",
    "        .max('duration') \\\n",
    "    .orderBy('max(duration)', ascending=False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7137f449-d421-4acb-a182-131a1fa65603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|pickup_date|          duration|\n",
      "+-----------+------------------+\n",
      "| 2019-10-28|          631152.5|\n",
      "| 2019-10-11|          631152.5|\n",
      "| 2019-10-31| 87672.44083333333|\n",
      "| 2019-10-01| 70128.02805555555|\n",
      "| 2019-10-17|            8794.0|\n",
      "| 2019-10-26| 8784.166666666666|\n",
      "| 2019-10-30|1465.5344444444445|\n",
      "| 2019-10-25|1057.8266666666666|\n",
      "| 2019-10-02| 770.2313888888889|\n",
      "| 2019-10-23| 746.6166666666667|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    to_date(pickup_datetime) AS pickup_date,\n",
    "    MAX((CAST(dropoff_datetime AS LONG) - CAST(pickup_datetime AS LONG)) / 3600) AS duration\n",
    "FROM \n",
    "    fhv_2019_10\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT 10;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f71704f-3e21-492f-9fbd-585719a7c6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-03 14:35:00--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 192.30.255.112\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240303%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240303T223500Z&X-Amz-Expires=300&X-Amz-Signature=9ab9e7f2c8284b80872b58567435b20fa6783bb8bf48d471c641024a7ec61447&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-03 14:35:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240303%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240303T223500Z&X-Amz-Expires=300&X-Amz-Signature=9ab9e7f2c8284b80872b58567435b20fa6783bb8bf48d471c641024a7ec61447&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2024-03-03 14:35:00 (5.74 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import taxi_zone_lookup.csv\n",
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "835917cd-9e7d-46ec-b3a8-0270c99e061a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 taxi_zone_lookup.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf027654-5e46-40e8-9891-f851f55b209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2b3676c-9f2c-4ee4-b098-6ba9b79a1fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('LocationID', StringType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zone.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4529ad96-4a29-4e97-b96b-15af80c67a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hy/Documents/App/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_zone.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1f4d2ca-f354-44e6-84b8-98a65b922e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM zones LIMIT 30;\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31d55f21-8b2b-4fd7-8de7-243588e94c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number',\n",
       " 'pickup_date',\n",
       " 'dropoff_date']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1195db07-beeb-4d52-9c4e-e8850bcf648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         pickup_zone|count|\n",
      "+--------------------+-----+\n",
      "|         Jamaica Bay|    1|\n",
      "|Governor's Island...|    2|\n",
      "| Green-Wood Cemetery|    5|\n",
      "|       Broad Channel|    8|\n",
      "|     Highbridge Park|   14|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 6: The query to find least frequent pickup zone\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    pul.Zone AS pickup_zone,\n",
    "    COUNT(1) AS count\n",
    "FROM \n",
    "    fhv_2019_10 fhv LEFT JOIN zones pul ON fhv.PULocationID = pul.LocationID\n",
    "                      LEFT JOIN zones dol ON fhv.DOLocationID = dol.LocationID\n",
    "GROUP BY \n",
    "    pickup_zone\n",
    "ORDER BY\n",
    "    count ASC\n",
    "LIMIT 5;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc0623-b718-422f-8810-01a258d70a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
